{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_7_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHoSDyYpdh-s"
      },
      "source": [
        "Assignment 7: Neural Networks using Keras and Tensorflow Please see the associated document for questions\n",
        "\n",
        "If you have problems with Keras and Tensorflow on your local installation please make sure they are updated. On Google Colab this notebook runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02ZYZ-WmdhwH"
      },
      "source": [
        "# imports\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Lambda, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJRCoRmew8Zd"
      },
      "source": [
        "# Hyper-parameters data-loading and formatting\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I3g1RrZ0wpI"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UswCCQLS0s1I"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(lbl_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(lbl_test, num_classes)\n",
        "\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Aer42gk1W9"
      },
      "source": [
        "## Define model ##\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=tf.keras.optimizers.SGD(lr = 0.1),\n",
        "        metrics=['accuracy'],)\n",
        "\n",
        "fit_info = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=1,\n",
        "           validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting\n",
        "ep = [1,2,3,4,5,6,7,8,9,10]\n",
        "train_accuracy = fit_info.history['accuracy']\n",
        "val_accuracy = fit_info.history['val_accuracy']\n",
        "\n",
        "plt.plot(ep,train_accuracy, label = \"train accuracy\")\n",
        "plt.plot(ep,val_accuracy, label = \"val accuracy\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jZpFeOVyQgce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I2Bkk_rhUnH"
      },
      "source": [
        "### Question 4) Auto-Encoder for denoising\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO0HxKeJ7WFw"
      },
      "source": [
        "import numpy as np\n",
        "def salt_and_pepper(input, noise_level=0.5):\n",
        "    \"\"\"\n",
        "    This applies salt and pepper noise to the input tensor - randomly setting bits to 1 or 0.\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : tensor\n",
        "        The tensor to apply salt and pepper noise to.\n",
        "    noise_level : float\n",
        "        The amount of salt and pepper noise to add.\n",
        "    Returns\n",
        "    -------\n",
        "    tensor\n",
        "        Tensor with salt and pepper noise applied.\n",
        "    \"\"\"\n",
        "    # salt and pepper noise\n",
        "    a = np.random.binomial(size=input.shape, n=1, p=(1 - noise_level))\n",
        "    b = np.random.binomial(size=input.shape, n=1, p=0.5)\n",
        "    c = (a==0) * b\n",
        "    return input * a + c\n",
        "\n",
        "\n",
        "#data preparation\n",
        "flattened_x_train = x_train.reshape(-1,784)\n",
        "flattened_x_train_seasoned = salt_and_pepper(flattened_x_train, noise_level=0.4)\n",
        "\n",
        "flattened_x_test = x_test.reshape(-1,784)\n",
        "flattened_x_test_seasoneed = salt_and_pepper(flattened_x_test, noise_level=0.4)\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def increase_noise(test,noise):\n",
        "  x_test = salt_and_pepper(test,noise_level = noise)\n",
        "\n",
        "  return x_test\n"
      ],
      "metadata": {
        "id": "Lli6Ueqtvv5C"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GZtZH4ScQeN"
      },
      "source": [
        "latent_dim = 96  \n",
        "\n",
        "input_image = keras.Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_image)\n",
        "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
        "\n",
        "\n",
        "decoded = Dense(128, activation='relu')(encoded) \n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "autoencoder = keras.Model(input_image, decoded) \n",
        "encoder_only = keras.Model(input_image,encoded) \n",
        "\n",
        "encoded_input = keras.Input(shape=(latent_dim,))\n",
        "decoder_layer = Sequential(autoencoder.layers[-2:])\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss = 'binary_crossentropy')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56iJOKNIKfuB"
      },
      "source": [
        "## changed input\n",
        "fit_info_AE = autoencoder.fit(flattened_x_train_seasoned, flattened_x_train,\n",
        "                epochs=32,\n",
        "                batch_size=64,\n",
        "                shuffle=True,\n",
        "                validation_data=(flattened_x_test_seasoneed, flattened_x_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code for generating random images: original, seasoned and denoised"
      ],
      "metadata": {
        "id": "h1D4K1dSPLqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_seasoned = increase_noise(flattened_x_test,noise = 0.8)\n",
        "\n",
        "\n",
        "num_images = 4\n",
        "np.random.seed(42)\n",
        "random_test_images = np.random.randint(flattened_x_test.shape[0], size=num_images)\n",
        "\n",
        "decoded_img = autoencoder.predict(x_seasoned)\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "\n",
        "for i, image_idx in enumerate(random_test_images):\n",
        "    # plot original image\n",
        "    ax = plt.subplot(3, num_images, i + 1)\n",
        "    plt.imshow(flattened_x_test[image_idx].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "    # plot seasoned image\n",
        "    ax = plt.subplot(3, num_images, num_images + i + 1)\n",
        "    plt.imshow(x_seasoned[image_idx].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # plot reconstructed image\n",
        "    ax = plt.subplot(3, num_images, 2*num_images + i + 1)\n",
        "    plt.imshow(decoded_img[image_idx].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dRwNOkA14OTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification using denoising"
      ],
      "metadata": {
        "id": "rdbfxdwLZPur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "loaded_model = pickle.load(open('final_model.sav', 'rb'))\n"
      ],
      "metadata": {
        "id": "C-pORjaSSNTJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "noise = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "\n",
        "score_noise = []\n",
        "score_denoise = []\n",
        "\n",
        "for i in noise:\n",
        "\n",
        "  # adding noise\n",
        "  train_noise = salt_and_pepper(x_train,i)\n",
        "  test_noise = salt_and_pepper(x_test,i)\n",
        "\n",
        "  #denoising\n",
        "  train_denoised = autoencoder.predict(train_noise.reshape(-1,784))\n",
        "  test_denoised = autoencoder.predict(test_noise.reshape(-1,784))\n",
        "\n",
        "  train_denoised = train_denoised.reshape(60000,28,28,1)\n",
        "  test_denoised = test_denoised.reshape(10000,28,28,1)\n",
        "\n",
        "  # fit model with noisy data\n",
        "  fit_noise = model.fit(train_noise, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=1,\n",
        "           validation_data=(test_noise, y_test))\n",
        "  score_noise.append(model.evaluate(test_noise, y_test, verbose=0)[1])\n",
        "\n",
        "  # fit model with denoised data\n",
        "  fit_denoise = model.fit(train_denoised, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=1,\n",
        "           validation_data=(test_denoised, y_test))\n",
        "  score_denoise.append(model.evaluate(test_denoised, y_test, verbose=0)[1])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yXaKQqg-ZO_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting noise vs denoised\n",
        "plt.plot(noise,score_noise, label = \"noise\")\n",
        "plt.plot(noise,score_denoise, label = \"denoise\")\n",
        "plt.xlabel('Noise-level')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ja8yntX-fqwR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}